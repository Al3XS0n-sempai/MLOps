# MLOPS
Репозиторий с домашними заданиями по курсу MLOPS 2024-2025.  
Студент: Цхай Александр  
Курс: 5  
Группа: М05-411в  
Кафедра: Банковские и информационные технологии (БиТ)  

## Table of content:
1. [Структура репозитория](#info)
2. [Статусы домашних работ](#statuses)
3. [Условия домашних работ](#statements)
4. [Комментарии к решениям](#comments)

---  
<a id="info"></a>

### Структура репозитория
Каждая домашняя работа лежит в соответствующей папке. До merg'а pull request'а и в соответствующей ветке.  
То есть домашняя работа номер N после merg'а будет лежать в папке hw_N в ветке master. До merg'а в этой же папке, но в ветке hw/N.

---  
<a id="statuses"></a>
### Статусы домашних работ. 
**\+** значит что домашняя работа в работе  
**?** обозначает открытый PR  
**X** обозначат выполненое и соответсвенно влитое в мастер ветку задание  
[ ? ] 1 домашняя работа
[ ? ] 2 домашняя работа
[ ? ] 3 домашняя работа


---
<a id="statements"></a>

### Условия домашних работ  
1. TLDR: Python пакет с биндингами
    <details>
    <summary> Полное условие </summary>
    Данное домашнее задание покрывает следующие темы:  
    Python bindings
    Python packaging
    Docker  

    Вам предстоит написать совсем немного кода на С++, обернуть в pybind, собрать python пакет, протестировать в docker. Эту задачу стоит декомпозировать на несколько шагов:    
    **Step-1 [2 балла]**: Функция на C++
    Каждому предстоит выбрать свою тему [тут](https://docs.google.com/spreadsheets/d/1Cb834Zyeg2NrO88KShiEpOXpqd0kZJSDzkfPMZl6_4Y/edit?usp=sharing).   
    **Step-2 [2 балла]**: Pybind, cmake
    Далее используя pybind (пример) указываете какие функции будут доступны в качестве биндингов. Затем пишите Makefile в котором указываете команды для компиляции c++ кода (пример)  
    **Step-3** [3 балла]: Подготовка пакета
    Вам понадобится написать pyproject.toml с минимальной необходимой секцией [build-system], а затем подготовить setup.py  
    **Step-4** [3 балла]: Установка пакета
    Командой python3 -m build получаем .whl файл, затем устанавливаем его через pip install <path to .whl>  
    **Step-5** [1 балл]: Проверка работоспособности
    Подготовьте короткий скрипт с тестами, которые сравнивали бы результаты ваших биндингов и эталонных реализаций из каких-либо библиотек.  
      
    Шаг 4 должен выполняться внутри Dockerfile; Шаг 5 - внутри запущенного докер-контейнера полученного на шаге 4.
    </details>
2. TLDR: Hydra + DVC
    <details>
    <summary> Полное условие </summary>
    Используя результаты ДЗ-1, имплементируйте цикл обучения на pytorch lightning, используйте hydra как точку входа, подключите DVC для хранения файлов  
      
    Definition of done:  
    Step-1 [1 балл]: Используя python модуль с биндингами напишите необходимый код для лайнтнинга pl.LightningDataModule, pl.LightningModule. Биндинги должны использоваться в подготовке данных (__getitem__ метод класса torch.utils.data.Dataset).  
    Step-2 [3 балла]: точка входа - скрипт train.py, под main guard - вызов единственного метода с декоратором hydra. Конфиги hydra - в отдельной директории, разбитые на логические файлы (в один .yaml нельзя). В коде нет никаких литератов/констант -- все значения должны быть получены из yaml с конфигом  
    Step-3 [3 балла]: подключен dvc (с любым из типов remote storage), в него загружено несколько файлов. Будет проверяться наличие и валидность /.dvc и .dvc файлов.  
    </details>
3. TLDR: ONNX+TENSORRT+TRITON
    <details>
    <summary> Полное условие </summary>
    НЕ ВМЕСТИЛОСЬ
    </details>



---  
<a id="comments"></a>

### Комментарии к решениям  
1. Можно скачать образ al3xs0n/relu_module:0.0.1 который я опубликовал в docker hub. После его запуска запустить скрипт который проведет тесты на производительность с использованием профайлера cProfile. По результатам видно что моя реализация получилась очень не оптимальной относительно бенчмарков (pytorch, tensorflow.keras). Я виже несколько причин почему:
    - Во первых моя реализация написана на c++ с использованием `std::vector<double>`. А не чистого c
    - Мой модуль оперирует объектами типа `list[float]` которые как мы знаем очень не эффективные
    - torch и tensorflow контрибьютят несколько десятков людей (по поему), а я один и у меня не так много времени((
    - Я кончено не сравнил с реализацией на питоне, но думаю что уж её то я точно обгоню

    Подробнее о самом решение можно прочитать в [README](hw_1/README.md) внутри папки с домашним заданием
2. Если честно не совсем понял насколько осмысленны должны быть модель и данные в задаче. Поэтому написал полный рандом в плане архитектуры модели (по сути 2 слойная сетка) и данных (2 столбца  фича и лейбл). Но реализовал загрузку в DVC (локальная папка) и обучением через Hydra с использоваеним конфигов по максимум где это было разумно.  

3. Не успел посчитать performance для всех моделей успел только для [ONNX](/hw_3/perf_model_ONNX), а когда начал считать для TRT моделей у меня процесс получал kill сигнал и откисал. По итогу так и не смогу рассчитать latency для остальных моделей. Для подсчета FLOPs я воспользовался библиотекой fvcore. Результат можно посмотреть в [тут](/hw_3/layers) там же записано какие-слои являются ограничеными по памяти, а какие ограничеными пропускной способностью (thrashhold на batch'и 38 был взят из чата).